{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS111 Lecture 3 - Demo #2\n",
    "## Spring 2023, Z. Matni\n",
    "\n",
    "## `A = LU` Factorization\n",
    "\n",
    "### Again, we'll start off by importing numpy and the linear algebra class (linalg) from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as npla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LU Factorization\n",
    "*Consider a SQUARE 4x4 matrix A as shown in lecture...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      " [[ 2.   7.   1.   8. ]\n",
      " [ 1.   5.5  8.5  5. ]\n",
      " [ 0.   1.  12.   2.5]\n",
      " [-1.  -4.5 -4.5  3.5]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [ 2. ,  7. ,  1. ,  8. ],\n",
    "    [ 1. ,  5.5,  8.5,  5. ],\n",
    "    [ 0. ,  1. , 12. ,  2.5],\n",
    "    [-1. , -4.5, -4.5,  3.5]])\n",
    "print(\"A =\\n\", A,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Recall we found U and L in the exercise we did in lecture.*\n",
    "\n",
    "We used Gaussian elimination on the blackboard to triangularize A, giving us the matrix U.\n",
    "\n",
    "During Gaussian elimination, we wrote down the multipliers in a lower triangular array,\n",
    "then put ones on the diagonal, giving us L.\n",
    "\n",
    "L and U were found to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U =\n",
      " [[2 7 1 8]\n",
      " [0 2 8 1]\n",
      " [0 0 8 2]\n",
      " [0 0 0 8]] \n",
      "\n",
      "L=\n",
      " [[ 1.   0.   0.   0. ]\n",
      " [ 0.5  1.   0.   0. ]\n",
      " [ 0.   0.5  1.   0. ]\n",
      " [-0.5 -0.5  0.   1. ]]\n"
     ]
    }
   ],
   "source": [
    "U = np.array([[2,7,1,8],[0,2,8,1],[0,0,8,2],[0,0,0,8]])\n",
    "L = np.array([[1,0,0,0],[.5,1,0,0],[0,.5,1,0],[-.5,-.5,0,1]])\n",
    "print(\"U =\\n\", U, \"\\n\\nL=\\n\", L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see if that works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L.U:\n",
      " [[ 2.   7.   1.   8. ]\n",
      " [ 1.   5.5  8.5  5. ]\n",
      " [ 0.   1.  12.   2.5]\n",
      " [-1.  -4.5 -4.5  3.5]]\n",
      "\n",
      "vs. original A:\n",
      " [[ 2.   7.   1.   8. ]\n",
      " [ 1.   5.5  8.5  5. ]\n",
      " [ 0.   1.  12.   2.5]\n",
      " [-1.  -4.5 -4.5  3.5]]\n",
      "np.residual norm 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy.linalg as npla\n",
    "print(\"L.U:\\n\", L @ U)\n",
    "print()\n",
    "print(\"vs. original A:\\n\", A)\n",
    "print(\"np.residual norm\", npla.norm(A - L@U))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just HOW different are these 2 results (LU vs A)???\n",
    "#### Are there any \"residuals\"???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residual:\n",
      " [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "rel.norm of res.:\n",
      " 0.0\n"
     ]
    }
   ],
   "source": [
    "# The \"residual\" is the difference:\n",
    "print(\"residual:\\n\", L@U - A)\n",
    "\n",
    "# If we want to \"boil\" this down to a single scalar number AND compare it to the \"original\",\n",
    "# then, we want to find the \"RELATIVE RESIDUAL\" value:\n",
    "print(\"rel.norm of res.:\\n\", npla.norm(L@U - A)/npla.norm(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note how \"clean\" the residual is (i.e. it's exactly 0)*\n",
    "#### So... They're exactly the same!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LU FACTORIZATION\n",
    "### Create a function to automate this factorization technique\n",
    "**Create a function LUfactorNoPiv() that will take in a matrix A and return its L and U factors**\n",
    "\n",
    "*The NoPiv is for \"no pivoting needed\" - we'll cover that AFTER we figure this one out...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LUfactorNoPiv(A):\n",
    "    \"\"\"Factor a square matrix, A == L @ U (no partial pivoting)\n",
    "    Parameters: \n",
    "      A: the matrix.\n",
    "    Outputs (in order):\n",
    "      L: the lower triangular factor, same dimensions as A, with ones on the diagonal\n",
    "      U: the upper triangular factor, same dimensions as A\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check the input - matrix A has to be square\n",
    "    m, n = A.shape\n",
    "    assert m == n, 'input matrix A must be square'\n",
    "    \n",
    "    # Make a copy of the matrix that we will transform into L and U\n",
    "    # This is to ensure we can operate with floating-point numbers \n",
    "    # deep copy, set type to 64 bit floating point numbers\n",
    "    LU = A.astype(np.float64).copy()\n",
    "    \n",
    "    # Go through the algorithm:\n",
    "    # Eliminate each column in turn\n",
    "\n",
    "    #Start at 0 go to n - 1\n",
    "    #If went to (1,5) will go to 1234, (1,5,2) step of each for loop -> 13\n",
    "    for piv_col in range(n):\n",
    "            \n",
    "        # Update the rest of the matrix\n",
    "        # This routine creates a combination of the L and U matrices in one matrix (called LU here)\n",
    "        # Then L and U are separated from LU\n",
    "        pivot = LU[piv_col, piv_col]\n",
    "        assert pivot != 0., \"pivot is zero, can't continue\"\n",
    "        \n",
    "        for row in range(piv_col + 1, n):\n",
    "            multiplier = LU[row, piv_col] / pivot\n",
    "            LU[row, piv_col] = multiplier\n",
    "            LU[row, (piv_col+1):] -= multiplier * LU[piv_col, (piv_col+1):]\n",
    "    # Separate L and U in the result\n",
    "    # .triu() makes the lower-triangle half of a matrix all zeros\n",
    "    U = np.triu(LU)\n",
    "    L = LU - U + np.eye(n)\n",
    "        \n",
    "    return (L, U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A\n",
      " [[ 2.   7.   1.   8. ]\n",
      " [ 1.   5.5  8.5  5. ]\n",
      " [ 0.   1.  12.   2.5]\n",
      " [-1.  -4.5 -4.5  3.5]] \n",
      "\n",
      "L\n",
      " [[ 1.   0.   0.   0. ]\n",
      " [ 0.5  1.   0.   0. ]\n",
      " [ 0.   0.5  1.   0. ]\n",
      " [-0.5 -0.5  0.   1. ]] \n",
      "\n",
      "U\n",
      " [[2. 7. 1. 8.]\n",
      " [0. 2. 8. 1.]\n",
      " [0. 0. 8. 2.]\n",
      " [0. 0. 0. 8.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [ 2. ,  7. ,  1. ,  8. ],\n",
    "    [ 1. ,  5.5,  8.5,  5. ],\n",
    "    [ 0. ,  1. , 12. ,  2.5],\n",
    "    [-1. , -4.5, -4.5,  3.5]])\n",
    "\n",
    "#Alternative to try:\n",
    "#A = np.array([[1, 2, 3], [1,1,1], [-1,1,2]])\n",
    "\n",
    "L,U = LUfactorNoPiv(A)\n",
    "print(\"\\nA\\n\", A, \"\\n\\nL\\n\", L, \"\\n\\nU\\n\", U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note how the results of the 4x4 compare perfectly to the manual calculation we had done earlier in lecture.*\n",
    "\n",
    "***But will this work on ANY square matrix!!??? (nope - we'll see that in the next lecture!)***"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "138833874f2dc7c1a2fe589d9c55b0aff635bc609cbe7c4d1d123c8b54c76836"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
