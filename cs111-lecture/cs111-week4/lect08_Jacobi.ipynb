{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jacobi's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as npla\n",
    "\n",
    "# New additions!\n",
    "import scipy\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do a simple Ax = b problem with a 3x3 matrix A\n",
    "# Normally, you'd employ a MUCH larger matrix with Jacobi's Method...\n",
    "\n",
    "A = np.array([[4, -1, -1], [-2, 6, 1], [-1, 1, 7]])\n",
    "b = np.array([3, 9, -6])\n",
    "print(\"A =\\n\", A, \"\\n\\nb =\", b)\n",
    "\n",
    "# What's the ACTUAL (ideal) solution for x (not iteration, just straight-out solution)??\n",
    "xideal = npla.solve(A,b)\n",
    "print(\"\\nIf Ax = b, then x = \", xideal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Jacobi's Method - the Matrix view:\n",
    "\n",
    "*What do you need to start off with? See this:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dimensions of matrix A:\n",
    "m, n = A.shape\n",
    "\n",
    "# Get the diagonals as a vector d:\n",
    "d = A.diagonal()\n",
    "\n",
    "# Convert that diagonals vector d into a diagonal MATRIX D:\n",
    "D = np.diag(d)\n",
    "\n",
    "print(\"\\nm = \", m, \";\",\"n = \", n, \"\\n\")\n",
    "print(\"d =\\n\", d, \"\\n\")\n",
    "print(\"D =\\n\", D, \"\\n\")\n",
    "\n",
    "# Create matrix C, which is A WITHOUT the diagonals\n",
    "C = A - D\n",
    "print(\"C =\\n\", C, \"\\n\")\n",
    "\n",
    "# Let's make an initial guess: x = 0\n",
    "x = np.zeros(n)\n",
    "print (\"inital guess for x, i.e. x[0] = \", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We KNOW (this is like \"cheating\" b/c we ran `npla.solve()`) that `x =  [1, 2, -1]`\n",
    "\n",
    "***So let's improve on the initial guess of x = [0,0,0]:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnew = (b - C @ x) / d\n",
    "print( \"x[1] = \", xnew )\n",
    "\n",
    "error = npla.norm( A@xnew - b)\n",
    "print(\"error:\", error)\n",
    "\n",
    "# residual = xnew - xideal\n",
    "# error = npla.norm( xnew - xideal )\n",
    "# relres = npla.norm( xnew - xideal ) / npla.norm( xideal )\n",
    "# print( \"residual:\", residual, \"\\nerror:\", error, \"\\nrelres:\", relres )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ok - better, but not close enough (relative residual is too high). Do it again!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnew = (b - C @ xnew) / d\n",
    "print( \"x[2] = \", xnew )\n",
    "\n",
    "error = npla.norm( A@xnew - b)\n",
    "print(\"error:\", error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ok - AGAIN, it's better, but not close enough (relative residual is too high). Do it again!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnew = (b - C @ xnew) / d\n",
    "print( \"x[3] = \", xnew )\n",
    "\n",
    "error = npla.norm( A@xnew - b)\n",
    "print(\"error:\", error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok - you see where this is going? Better do a loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Again, start with our initial guess of [0,0,0]:\n",
    "x = np.zeros(3)\n",
    "\n",
    "for i in range( 100 ):\n",
    "    x = (b - C @ x) / d\n",
    "    error = npla.norm( A@x - b)\n",
    "    print( \"iteration\", i + 1, \"x:\", x, \", error:\" ,error )\n",
    "    if error <= 1e-8:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see from the results above that if we (arbitrarily) chose a threshold of 1e-8, that iteration number 19 would get us just below that!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***BUT!!!*** Jacobi's Method does not always converge...! :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example that does NOT converge using J. Method:\n",
    "\n",
    "A = np.array([[1,2],[3,4]])\n",
    "b = np.array([3,7])\n",
    "print(\"A:\\n\", A)\n",
    "print(\"\\nb = \", b)\n",
    "x = npla.solve(A, b)\n",
    "print(\"\\nx (ideal) = \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get d, D, and C:\n",
    "d = A.diagonal()\n",
    "D = np.diag(d)\n",
    "C = A - D\n",
    "\n",
    "#Start with our initial guess of [0,0]:\n",
    "x = np.zeros(2)\n",
    "\n",
    "for i in range( 100 ):\n",
    "    x = (b - C @ x) / d\n",
    "    error = npla.norm( A@x - b)\n",
    "    print( \"iteration\", i + 1, \"x:\", x, \", error:\" ,error )\n",
    "    if error <= 1e-8:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We see from the results above that we NEVER CONVERGE!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We could have avoided this \"heartache\" by checking the \"Spectral Radius\" of the Matrix A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check spectral radius\n",
    "m = npla.inv(D)@C\n",
    "evs = npla.eig(m)[0]\n",
    "print(evs)\n",
    "\n",
    "if max(evs) < 1:\n",
    "    print(\"Spectral radius < 1. Will converge.\")\n",
    "else:\n",
    "    print(\"Spectral radius >= 1. Will not converge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check it again for our earlier matrix A (that DID converge)\n",
    "# We'll call it matrix Z here, just to distinguish it from matrix A above:\n",
    "\n",
    "Z = np.array([[4, -1, -1], [-2, 6, 1], [-1, 1, 7]])\n",
    "d = Z.diagonal()\n",
    "D = np.diag(d)\n",
    "C = Z - D\n",
    "\n",
    "# Check spectral radius\n",
    "m = npla.pinv(D)@C\n",
    "evs = npla.eig(m)[0]\n",
    "print(evs)\n",
    "\n",
    "if max(evs) < 1:\n",
    "    print(\"Spectral radius < 1. Will converge.\")\n",
    "else:\n",
    "    print(\"Spectral radius >= 1. Will not converge.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a function that can do all of this for us!\n",
    "\n",
    "**Presenting function `Jsolve()`:** \\\n",
    "**It takes in our matrix `A`, vector `b`and gives us the best solution for `x` (plus the `resrel`)** \\\n",
    "\n",
    "It should also have as arguments: a threshold tolerance (default = 1e-8), maximum number of iterations (default = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATTENTION:\n",
    "\n",
    "**`Jsolve()` employs SPARSE MATRICES so that it's use can be extended to very large, sparse matrices, as well as, more \"ordinary\" ones.**\n",
    "\n",
    "This means that BEFORE using it, make sure to convert an np.array() type matrix into a sparse one (how to do that is illustrated all the way below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jsolve(A, b, tol = 1e-8, max_iters = 1000, callback = None):\n",
    "    \"\"\"Solve a linear system Ax = b for x by the Jacobi iterative method.\n",
    "    Parameters: \n",
    "      A: the matrix.\n",
    "      b: the right-hand side vector.\n",
    "      tol = 1e-8: the relative residual at which to stop iterating.\n",
    "      max_iters = 1000: the maximum number of iterations to do. \n",
    "      callback = None: a user function to call at every iteration. \n",
    "        The callback function has arguments 'x', 'iteration', and 'residual'\n",
    "    Outputs (in order):\n",
    "      x: the computed solution\n",
    "      rel_res: list of relative residual norms at each iteration.\n",
    "        The number of iterations actually done is len(rel_res) - 1\n",
    "    \"\"\"\n",
    "    # Check the input\n",
    "    m, n = A.shape\n",
    "    assert m == n, \"matrix must be square\"\n",
    "    bn, = b.shape\n",
    "    assert bn == n, \"rhs vector must be same size as matrix\"\n",
    "\n",
    "    # Split A into diagonal D plus off-diagonal C\n",
    "    d = A.diagonal()         # diagonal elements of A as a vector\n",
    "    C = A.copy()             # copy of A ...\n",
    "    C.setdiag(np.zeros(n))   # ... without the diagonal\n",
    "    \n",
    "    # Initial guess: x = 0\n",
    "    x = np.zeros(n)\n",
    "\n",
    "    # Vector of relative residuals\n",
    "    # Relative residual is norm(residual)/norm(b)\n",
    "    # Intitial residual is b - Ax for x=0, or b\n",
    "    rel_res = [1.0]\n",
    "        \n",
    "    # Call user function if specified\n",
    "    if callback is not None:\n",
    "        callback(x = x, iteration = 0, residual = 1)\n",
    "\n",
    "    # Iterate\n",
    "    for k in range(1, max_iters+1):\n",
    "        # New x\n",
    "        x = (b - C @ x) / d\n",
    "\n",
    "        # Record relative residual (this can be done instead of error)\n",
    "        # Remember: rel_res = error / some_relative_reference\n",
    "        this_rel_res = npla.norm(b - A @ x) / npla.norm(b)\n",
    "        rel_res.append(this_rel_res)\n",
    "                \n",
    "        # Call user function if specified\n",
    "        if callback is not None:\n",
    "            callback(x = x, iteration = k, residual = this_rel_res)\n",
    "                        \n",
    "        # Stop if within tolerance    \n",
    "        if this_rel_res <= tol:\n",
    "            break\n",
    "            \n",
    "    return (x, rel_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[4, -1, -1], [-2, 6, 1], [-1, 1, 7]])\n",
    "b = np.array([3, 9, -6])\n",
    "print(\"A:\\n\", A)\n",
    "print(\"\\nb:\\n\", b)\n",
    "x = npla.solve(A, b)\n",
    "print(\"\\nIdeal x (so we can compare against it):\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run it using Jacobi - note, Jsolve() requires A to be a sparse matrix\n",
    "A = sparse.csr_matrix(A)\n",
    "\n",
    "print(\"x: \\n\", Jsolve(A, b)[0])\n",
    "print(\"\\nAll iterated residuals: \\n\", Jsolve(A, b)[1])\n",
    "\n",
    "# To see just the last residual:\n",
    "# NOTE: [1] indicates element 1 of the function return, which is a list,\n",
    "#       [-1] indicates the LAST element in that list.\n",
    "\n",
    "print(\"\\nLast residual: \", Jsolve(A,b)[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[4, 0, 1, 0], [2, 7, 7, 2], [1, 1, 4, 4], [0, 0, 2, 6]])\n",
    "b = np.array([1, 2, 3, 4])\n",
    "print(npla.solve(A,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = A.diagonal()\n",
    "D = np.diag(d)\n",
    "C = A - D\n",
    "\n",
    "# Check spectral radius\n",
    "m = npla.pinv(D)@C\n",
    "evs = npla.eig(m)[0]\n",
    "print(evs)\n",
    "\n",
    "if max(evs) < 1:\n",
    "    print(\"Spectral radius < 1. Will converge.\")\n",
    "else:\n",
    "    print(\"Spectral radius >= 1. Will not converge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run it using Jacobi - note, Jsolve() requires A to be a sparse matrix\n",
    "A = sparse.csr_matrix(A)\n",
    "solution = Jsolve(A, b, tol = 1e-8)\n",
    "print(\"x: \\n\",solution[0])\n",
    "print(\"\\nAll iterated residuals: \\n\", solution[1])\n",
    "print(\"length = \", len(solution[1]))\n",
    "print(\"\\nLast residual: \", solution[1][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
