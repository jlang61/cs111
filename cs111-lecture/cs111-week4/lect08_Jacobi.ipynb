{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jacobi's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as npla\n",
    "\n",
    "# New additions!\n",
    "import scipy\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      " [[ 4 -1 -1]\n",
      " [-2  6  1]\n",
      " [-1  1  7]] \n",
      "\n",
      "b = [ 3  9 -6]\n",
      "\n",
      "If Ax = b, then x =  [ 1.  2. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Let's do a simple Ax = b problem with a 3x3 matrix A\n",
    "# Normally, you'd employ a MUCH larger matrix with Jacobi's Method...\n",
    "\n",
    "A = np.array([[4, -1, -1], [-2, 6, 1], [-1, 1, 7]])\n",
    "b = np.array([3, 9, -6])\n",
    "print(\"A =\\n\", A, \"\\n\\nb =\", b)\n",
    "\n",
    "# What's the ACTUAL (ideal) solution for x (not iteration, just straight-out solution)??\n",
    "xideal = npla.solve(A,b)\n",
    "print(\"\\nIf Ax = b, then x = \", xideal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Jacobi's Method - the Matrix view:\n",
    "\n",
    "*What do you need to start off with? See this:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "m =  3 ; n =  3 \n",
      "\n",
      "d =\n",
      " [4 6 7] \n",
      "\n",
      "D =\n",
      " [[4 0 0]\n",
      " [0 6 0]\n",
      " [0 0 7]] \n",
      "\n",
      "C =\n",
      " [[ 0 -1 -1]\n",
      " [-2  0  1]\n",
      " [-1  1  0]] \n",
      "\n",
      "inital guess for x, i.e. x[0] =  [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Get dimensions of matrix A:\n",
    "m, n = A.shape\n",
    "\n",
    "# Get the diagonals as a vector d:\n",
    "d = A.diagonal()\n",
    "\n",
    "# Convert that diagonals vector d into a diagonal MATRIX D:\n",
    "D = np.diag(d)\n",
    "\n",
    "print(\"\\nm = \", m, \";\",\"n = \", n, \"\\n\")\n",
    "print(\"d =\\n\", d, \"\\n\")\n",
    "print(\"D =\\n\", D, \"\\n\")\n",
    "\n",
    "# Create matrix C, which is A WITHOUT the diagonals\n",
    "C = A - D\n",
    "print(\"C =\\n\", C, \"\\n\")\n",
    "\n",
    "# Let's make an initial guess: x = 0\n",
    "x = np.zeros(n)\n",
    "print (\"inital guess for x, i.e. x[0] = \", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We KNOW (this is like \"cheating\" b/c we ran `npla.solve()`) that `x =  [1, 2, -1]`\n",
    "\n",
    "***So let's improve on the initial guess of x = [0,0,0]:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[1] =  [ 0.75        1.5        -0.85714286]\n",
      "error: 2.5557558089735486\n"
     ]
    }
   ],
   "source": [
    "xnew = (b - C @ x) / d\n",
    "print( \"x[1] = \", xnew )\n",
    "\n",
    "error = npla.norm( A@xnew - b)\n",
    "print(\"error:\", error)\n",
    "\n",
    "# residual = xnew - xideal\n",
    "# error = npla.norm( xnew - xideal )\n",
    "# relres = npla.norm( xnew - xideal ) / npla.norm( xideal )\n",
    "# print( \"residual:\", residual, \"\\nerror:\", error, \"\\nrelres:\", relres )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ok - better, but not close enough (relative residual is too high). Do it again!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[2] =  [ 0.91071429  1.89285714 -0.96428571]\n",
      "error: 0.5649747149841555\n"
     ]
    }
   ],
   "source": [
    "xnew = (b - C @ xnew) / d\n",
    "print( \"x[2] = \", xnew )\n",
    "\n",
    "error = npla.norm( A@xnew - b)\n",
    "print(\"error:\", error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ok - AGAIN, it's better, but not close enough (relative residual is too high). Do it again!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[3] =  [ 0.98214286  1.96428571 -0.99744898]\n",
      "error: 0.18013166779499973\n"
     ]
    }
   ],
   "source": [
    "xnew = (b - C @ xnew) / d\n",
    "print( \"x[3] = \", xnew )\n",
    "\n",
    "error = npla.norm( A@xnew - b)\n",
    "print(\"error:\", error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok - you see where this is going? Better do a loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 x: [ 0.75        1.5        -0.85714286] , error: 2.5557558089735486\n",
      "iteration 2 x: [ 0.91071429  1.89285714 -0.96428571] , error: 0.5649747149841555\n",
      "iteration 3 x: [ 0.98214286  1.96428571 -0.99744898] , error: 0.18013166779499973\n",
      "iteration 4 x: [ 0.99170918  1.99362245 -0.99744898] , error: 0.04021904343221404\n",
      "iteration 5 x: [ 0.99904337  1.99681122 -1.00027332] , error: 0.01798088346639159\n",
      "iteration 6 x: [ 0.99913448  1.99972668 -0.99968112] , error: 0.004522016940133618\n",
      "iteration 7 x: [ 1.00001139  1.99965835 -1.0000846 ] , error: 0.0024020931567846297\n",
      "iteration 8 x: [ 0.99989344  2.0000179  -0.99994957] , error: 0.0007811656507351477\n",
      "iteration 9 x: [ 1.00001708  1.99995607 -1.00001778] , error: 0.00038839902247926573\n",
      "iteration 10 x: [ 0.99998457  2.00000866 -0.99999128] , error: 0.0001478837545685464\n",
      "iteration 11 x: [ 1.00000434  1.99999341 -1.00000344] , error: 6.819334618850008e-05\n",
      "iteration 12 x: [ 0.99999749  2.00000202 -0.99999844] , error: 2.7833883358805923e-05\n",
      "iteration 13 x: [ 1.0000009   1.9999989  -1.00000065] , error: 1.2340172394882448e-05\n",
      "iteration 14 x: [ 0.99999956  2.00000041 -0.99999972] , error: 5.186169084537932e-06\n",
      "iteration 15 x: [ 1.00000017  1.99999981 -1.00000012] , error: 2.2584596030647313e-06\n",
      "iteration 16 x: [ 0.99999992  2.00000008 -0.99999995] , error: 9.609724436678894e-07\n",
      "iteration 17 x: [ 1.00000003  1.99999997 -1.00000002] , error: 4.151973519390588e-07\n",
      "iteration 18 x: [ 0.99999999  2.00000001 -0.99999999] , error: 1.776021794987169e-07\n",
      "iteration 19 x: [ 1.00000001  1.99999999 -1.        ] , error: 7.647241792580404e-08\n",
      "iteration 20 x: [ 1.  2. -1.] , error: 3.27856605189705e-08\n",
      "iteration 21 x: [ 1.  2. -1.] , error: 1.4096039382652177e-08\n",
      "iteration 22 x: [ 1.  2. -1.] , error: 6.049235103362937e-09\n"
     ]
    }
   ],
   "source": [
    "#Again, start with our initial guess of [0,0,0]:\n",
    "x = np.zeros(3)\n",
    "\n",
    "for i in range( 100 ):\n",
    "    x = (b - C @ x) / d\n",
    "    error = npla.norm( A@x - b)\n",
    "    print( \"iteration\", i + 1, \"x:\", x, \", error:\" ,error )\n",
    "    if error <= 1e-8:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see from the results above that if we (arbitrarily) chose a threshold of 1e-8, that iteration number 19 would get us just below that!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***BUT!!!*** Jacobi's Method does not always converge...! :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "\n",
      "b =  [3 7]\n",
      "\n",
      "x (ideal) =  [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Example that does NOT converge using J. Method:\n",
    "\n",
    "A = np.array([[1,2],[3,4]])\n",
    "b = np.array([3,7])\n",
    "print(\"A:\\n\", A)\n",
    "print(\"\\nb = \", b)\n",
    "x = npla.solve(A, b)\n",
    "print(\"\\nx (ideal) = \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 x: [3.   1.75] , error: 9.656603957913983\n",
      "iteration 2 x: [-0.5 -0.5] , error: 11.423659658795863\n",
      "iteration 3 x: [4.    2.125] , error: 14.484905936870975\n",
      "iteration 4 x: [-1.25 -1.25] , error: 17.135489488193794\n",
      "iteration 5 x: [5.5    2.6875] , error: 21.727358905306463\n",
      "iteration 6 x: [-2.375 -2.375] , error: 25.70323423229069\n",
      "iteration 7 x: [7.75    3.53125] , error: 32.59103835795969\n",
      "iteration 8 x: [-4.0625 -4.0625] , error: 38.55485134843604\n",
      "iteration 9 x: [11.125     4.796875] , error: 48.88655753693954\n",
      "iteration 10 x: [-6.59375 -6.59375] , error: 57.832277022654054\n",
      "iteration 11 x: [16.1875     6.6953125] , error: 73.3298363054093\n",
      "iteration 12 x: [-10.390625 -10.390625] , error: 86.74841553398107\n",
      "iteration 13 x: [23.78125     9.54296875] , error: 109.99475445811396\n",
      "iteration 14 x: [-16.0859375 -16.0859375] , error: 130.1226233009716\n",
      "iteration 15 x: [35.171875   13.81445312] , error: 164.99213168717094\n",
      "iteration 16 x: [-24.62890625 -24.62890625] , error: 195.18393495145742\n",
      "iteration 17 x: [52.2578125  20.22167969] , error: 247.48819753075642\n",
      "iteration 18 x: [-37.44335938 -37.44335938] , error: 292.77590242718617\n",
      "iteration 19 x: [77.88671875 29.83251953] , error: 371.2322962961346\n",
      "iteration 20 x: [-56.66503906 -56.66503906] , error: 439.1638536407792\n",
      "iteration 21 x: [116.33007812  44.2487793 ] , error: 556.848444444202\n",
      "iteration 22 x: [-85.49755859 -85.49755859] , error: 658.7457804611688\n",
      "iteration 23 x: [173.99511719  65.87316895] , error: 835.2726666663029\n",
      "iteration 24 x: [-128.74633789 -128.74633789] , error: 988.1186706917532\n",
      "iteration 25 x: [260.49267578  98.30975342] , error: 1252.9089999994544\n",
      "iteration 26 x: [-193.61950684 -193.61950684] , error: 1482.1780060376298\n",
      "iteration 27 x: [390.23901367 146.96463013] , error: 1879.3634999991816\n",
      "iteration 28 x: [-290.92926025 -290.92926025] , error: 2223.2670090564447\n",
      "iteration 29 x: [584.85852051 219.94694519] , error: 2819.0452499987723\n",
      "iteration 30 x: [-436.89389038 -436.89389038] , error: 3334.900513584667\n",
      "iteration 31 x: [876.78778076 329.42041779] , error: 4228.567874998158\n",
      "iteration 32 x: [-655.84083557 -655.84083557] , error: 5002.350770377001\n",
      "iteration 33 x: [1314.68167114  493.63062668] , error: 6342.851812497238\n",
      "iteration 34 x: [-984.26125336 -984.26125336] , error: 7503.5261555655015\n",
      "iteration 35 x: [1971.52250671  739.94594002] , error: 9514.277718745856\n",
      "iteration 36 x: [-1476.89188004 -1476.89188004] , error: 11255.289233348252\n",
      "iteration 37 x: [2956.78376007 1109.41891003] , error: 14271.416578118786\n",
      "iteration 38 x: [-2215.83782005 -2215.83782005] , error: 16882.93385002238\n",
      "iteration 39 x: [4434.67564011 1663.62836504] , error: 21407.124867178176\n",
      "iteration 40 x: [-3324.25673008 -3324.25673008] , error: 25324.40077503357\n",
      "iteration 41 x: [6651.51346016 2494.94254756] , error: 32110.687300767266\n",
      "iteration 42 x: [-4986.88509512 -4986.88509512] , error: 37986.601162550345\n",
      "iteration 43 x: [9976.77019024 3741.91382134] , error: 48166.0309511509\n",
      "iteration 44 x: [-7480.82764268 -7480.82764268] , error: 56979.901743825525\n",
      "iteration 45 x: [14964.65528536  5612.37073201] , error: 72249.04642672635\n",
      "iteration 46 x: [-11221.74146402 -11221.74146402] , error: 85469.85261573829\n",
      "iteration 47 x: [22446.48292804  8418.05609801] , error: 108373.56964008952\n",
      "iteration 48 x: [-16833.11219603 -16833.11219603] , error: 128204.77892360743\n",
      "iteration 49 x: [33669.22439206 12626.58414702] , error: 162560.3544601343\n",
      "iteration 50 x: [-25250.16829404 -25250.16829404] , error: 192307.16838541115\n",
      "iteration 51 x: [50503.33658808 18939.37622053] , error: 243840.53169020143\n",
      "iteration 52 x: [-37875.75244106 -37875.75244106] , error: 288460.7525781167\n",
      "iteration 53 x: [75754.50488213 28408.5643308 ] , error: 365760.7975353021\n",
      "iteration 54 x: [-56814.1286616 -56814.1286616] , error: 432691.1288671751\n",
      "iteration 55 x: [113631.25732319  42612.3464962 ] , error: 548641.1963029532\n",
      "iteration 56 x: [-85221.69299239 -85221.69299239] , error: 649036.6933007627\n",
      "iteration 57 x: [170446.38598479  63918.01974429] , error: 822961.7944544298\n",
      "iteration 58 x: [-127833.03948859 -127833.03948859] , error: 973555.0399511439\n",
      "iteration 59 x: [255669.07897718  95876.52961644] , error: 1234442.6916816446\n",
      "iteration 60 x: [-191750.05923288 -191750.05923288] , error: 1460332.559926716\n",
      "iteration 61 x: [383503.11846577 143814.29442466] , error: 1851664.037522467\n",
      "iteration 62 x: [-287625.58884933 -287625.58884933] , error: 2190498.839890074\n",
      "iteration 63 x: [575254.17769865 215720.94163699] , error: 2777496.0562837007\n",
      "iteration 64 x: [-431438.88327399 -431438.88327399] , error: 3285748.259835111\n",
      "iteration 65 x: [862880.76654798 323580.91245549] , error: 4166244.0844255504\n",
      "iteration 66 x: [-647158.82491098 -647158.82491098] , error: 4928622.389752666\n",
      "iteration 67 x: [1294320.64982197  485370.86868324] , error: 6249366.126638326\n",
      "iteration 68 x: [-970738.73736648 -970738.73736648] , error: 7392933.584628999\n",
      "iteration 69 x: [1941480.47473295  728055.80302486] , error: 9374049.189957488\n",
      "iteration 70 x: [-1456108.60604971 -1456108.60604971] , error: 11089400.376943497\n",
      "iteration 71 x: [2912220.21209943 1092083.20453729] , error: 14061073.784936232\n",
      "iteration 72 x: [-2184163.40907457 -2184163.40907457] , error: 16634100.565415245\n",
      "iteration 73 x: [4368329.81814914 1638124.30680593] , error: 21091610.67740435\n",
      "iteration 74 x: [-3276245.61361186 -3276245.61361186] , error: 24951150.84812287\n",
      "iteration 75 x: [6552494.22722371 2457185.96020889] , error: 31637416.016106527\n",
      "iteration 76 x: [-4914368.92041778 -4914368.92041778] , error: 37426726.27218431\n",
      "iteration 77 x: [9828740.84083557 3685778.44031334] , error: 47456124.02415979\n",
      "iteration 78 x: [-7371553.88062667 -7371553.88062667] , error: 56140089.40827646\n",
      "iteration 79 x: [14743110.76125335  5528667.16047001] , error: 71184186.0362397\n",
      "iteration 80 x: [-11057331.32094001 -11057331.32094001] , error: 84210134.1124147\n",
      "iteration 81 x: [22114665.64188002  8293000.24070501] , error: 106776279.05435953\n",
      "iteration 82 x: [-16585997.48141002 -16585997.48141002] , error: 126315201.16862205\n",
      "iteration 83 x: [33171997.96282004 12439499.86105751] , error: 160164418.5815393\n",
      "iteration 84 x: [-24878996.72211503 -24878996.72211503] , error: 189472801.75293308\n",
      "iteration 85 x: [49757996.44423006 18659249.29158627] , error: 240246627.87230897\n",
      "iteration 86 x: [-37318495.58317254 -37318495.58317254] , error: 284209202.6293996\n",
      "iteration 87 x: [74636994.16634509 27988873.43737941] , error: 360369941.80846345\n",
      "iteration 88 x: [-55977743.87475882 -55977743.87475882] , error: 426313803.9440995\n",
      "iteration 89 x: [1.11955491e+08 4.19833097e+07] , error: 540554912.7126951\n",
      "iteration 90 x: [-83966616.31213823 -83966616.31213823] , error: 639470705.9161493\n",
      "iteration 91 x: [1.67933236e+08 6.29749640e+07] , error: 810832369.0690428\n",
      "iteration 92 x: [-1.25949925e+08 -1.25949925e+08] , error: 959206058.8742237\n",
      "iteration 93 x: [2.51899853e+08 9.44624455e+07] , error: 1216248553.603564\n",
      "iteration 94 x: [-1.88924888e+08 -1.88924888e+08] , error: 1438809088.3113356\n",
      "iteration 95 x: [3.77849779e+08 1.41693668e+08] , error: 1824372830.405346\n",
      "iteration 96 x: [-2.83387332e+08 -2.83387332e+08] , error: 2158213632.4670033\n",
      "iteration 97 x: [5.66774668e+08 2.12540501e+08] , error: 2736559245.608019\n",
      "iteration 98 x: [-4.25080999e+08 -4.25080999e+08] , error: 3237320448.700505\n",
      "iteration 99 x: [8.50162001e+08 3.18810751e+08] , error: 4104838868.4120283\n",
      "iteration 100 x: [-6.37621499e+08 -6.37621499e+08] , error: 4855980673.050757\n"
     ]
    }
   ],
   "source": [
    "# Get d, D, and C:\n",
    "d = A.diagonal()\n",
    "D = np.diag(d)\n",
    "C = A - D\n",
    "\n",
    "#Start with our initial guess of [0,0]:\n",
    "x = np.zeros(2)\n",
    "\n",
    "for i in range( 100 ):\n",
    "    x = (b - C @ x) / d\n",
    "    error = npla.norm( A@x - b)\n",
    "    print( \"iteration\", i + 1, \"x:\", x, \", error:\" ,error )\n",
    "    if error <= 1e-8:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We see from the results above that we NEVER CONVERGE!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We could have avoided this \"heartache\" by checking the \"Spectral Radius\" of the Matrix A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.22474487 -1.22474487]\n",
      "Spectral radius >= 1. Will not converge.\n"
     ]
    }
   ],
   "source": [
    "# Check spectral radius\n",
    "m = npla.inv(D)@C\n",
    "evs = npla.eig(m)[0]\n",
    "print(evs)\n",
    "\n",
    "if max(evs) < 1:\n",
    "    print(\"Spectral radius < 1. Will converge.\")\n",
    "else:\n",
    "    print(\"Spectral radius >= 1. Will not converge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.42946179 -0.28202928 -0.14743251]\n",
      "Spectral radius < 1. Will converge.\n"
     ]
    }
   ],
   "source": [
    "# Check it again for our earlier matrix A (that DID converge)\n",
    "# We'll call it matrix Z here, just to distinguish it from matrix A above:\n",
    "\n",
    "Z = np.array([[4, -1, -1], [-2, 6, 1], [-1, 1, 7]])\n",
    "d = Z.diagonal()\n",
    "D = np.diag(d)\n",
    "C = Z - D\n",
    "\n",
    "# Check spectral radius\n",
    "m = npla.pinv(D)@C\n",
    "evs = npla.eig(m)[0]\n",
    "print(evs)\n",
    "\n",
    "if max(evs) < 1:\n",
    "    print(\"Spectral radius < 1. Will converge.\")\n",
    "else:\n",
    "    print(\"Spectral radius >= 1. Will not converge.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a function that can do all of this for us!\n",
    "\n",
    "**Presenting function `Jsolve()`:** \\\n",
    "**It takes in our matrix `A`, vector `b`and gives us the best solution for `x` (plus the `resrel`)** \\\n",
    "\n",
    "It should also have as arguments: a threshold tolerance (default = 1e-8), maximum number of iterations (default = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATTENTION:\n",
    "\n",
    "**`Jsolve()` employs SPARSE MATRICES so that it's use can be extended to very large, sparse matrices, as well as, more \"ordinary\" ones.**\n",
    "\n",
    "This means that BEFORE using it, make sure to convert an np.array() type matrix into a sparse one (how to do that is illustrated all the way below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jsolve(A, b, tol = 1e-8, max_iters = 1000, callback = None):\n",
    "    \"\"\"Solve a linear system Ax = b for x by the Jacobi iterative method.\n",
    "    Parameters: \n",
    "      A: the matrix.\n",
    "      b: the right-hand side vector.\n",
    "      tol = 1e-8: the relative residual at which to stop iterating.\n",
    "      max_iters = 1000: the maximum number of iterations to do. \n",
    "      callback = None: a user function to call at every iteration. \n",
    "        The callback function has arguments 'x', 'iteration', and 'residual'\n",
    "    Outputs (in order):\n",
    "      x: the computed solution\n",
    "      rel_res: list of relative residual norms at each iteration.\n",
    "        The number of iterations actually done is len(rel_res) - 1\n",
    "    \"\"\"\n",
    "    # Check the input\n",
    "    m, n = A.shape\n",
    "    assert m == n, \"matrix must be square\"\n",
    "    bn, = b.shape\n",
    "    assert bn == n, \"rhs vector must be same size as matrix\"\n",
    "\n",
    "    # Split A into diagonal D plus off-diagonal C\n",
    "    d = A.diagonal()         # diagonal elements of A as a vector\n",
    "    C = A.copy()             # copy of A ...\n",
    "    C.setdiag(np.zeros(n))   # ... without the diagonal\n",
    "    \n",
    "    # Initial guess: x = 0\n",
    "    x = np.zeros(n)\n",
    "\n",
    "    # Vector of relative residuals\n",
    "    # Relative residual is norm(residual)/norm(b)\n",
    "    # Intitial residual is b - Ax for x=0, or b\n",
    "    rel_res = [1.0]\n",
    "        \n",
    "    # Call user function if specified\n",
    "    if callback is not None:\n",
    "        callback(x = x, iteration = 0, residual = 1)\n",
    "\n",
    "    # Iterate\n",
    "    for k in range (max_iters):\n",
    "        # New x\n",
    "        x = (b - C @ x) / d\n",
    "\n",
    "        # Record relative residual (this can be done instead of error)\n",
    "        # Remember: rel_res = error / some_relative_reference\n",
    "        this_rel_res = npla.norm(b - A @ x) / npla.norm(b)\n",
    "        rel_res.append(this_rel_res)\n",
    "                \n",
    "        # Call user function if specified\n",
    "        if callback is not None:\n",
    "            callback(x = x, iteration = k+1, residual = this_rel_res)\n",
    "                        \n",
    "        # Stop if within tolerance    \n",
    "        if this_rel_res <= tol:\n",
    "            break\n",
    "            \n",
    "    return (x, rel_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[ 4 -1 -1]\n",
      " [-2  6  1]\n",
      " [-1  1  7]]\n",
      "\n",
      "b:\n",
      " [ 3  9 -6]\n",
      "\n",
      "Ideal x (so we can compare against it):\n",
      " [ 1.  2. -1.]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[4, -1, -1], [-2, 6, 1], [-1, 1, 7]])\n",
    "b = np.array([3, 9, -6])\n",
    "print(\"A:\\n\", A)\n",
    "print(\"\\nb:\\n\", b)\n",
    "x = npla.solve(A, b)\n",
    "print(\"\\nIdeal x (so we can compare against it):\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      " [ 1.00000001  1.99999999 -1.        ]\n",
      "\n",
      "All iterated residuals: \n",
      " [1.0, 0.22768482384372116, 0.0503319479919278, 0.01604740441421596, 0.003582997165407753, 0.001601864415303465, 0.00040285328778971063, 0.00021399546675719867, 6.959176731826758e-05, 3.4601335035126733e-05, 1.3174531968220623e-05, 6.075146130834141e-06, 2.479639411240011e-06, 1.099349933223233e-06, 4.6202066343380954e-07, 2.0119957277470704e-07, 8.561022957943247e-08, 3.698871997266093e-08, 1.5822059686393463e-08, 6.8127044622987766e-09]\n",
      "\n",
      "Last residual:  6.8127044622987766e-09\n"
     ]
    }
   ],
   "source": [
    "#Run it using Jacobi - note, Jsolve() requires A to be a sparse matrix\n",
    "A = sparse.csr_matrix(A)\n",
    "\n",
    "print(\"x: \\n\", Jsolve(A, b)[0])\n",
    "print(\"\\nAll iterated residuals: \\n\", Jsolve(A, b)[1])\n",
    "\n",
    "# To see just the last residual:\n",
    "# NOTE: [1] indicates element 1 of the function return, which is a list,\n",
    "#       [-1] indicates the LAST element in that list.\n",
    "\n",
    "print(\"\\nLast residual: \", Jsolve(A,b)[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.2406015  -0.0075188   0.03759398  0.65413534]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[4, 0, 1, 0], [2, 7, 7, 2], [1, 1, 4, 4], [0, 0, 2, 6]])\n",
    "b = np.array([1, 2, 3, 4])\n",
    "print(npla.solve(A,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.34137362e-01 -7.69197180e-01 -6.49401819e-02  2.64091342e-18]\n",
      "Spectral radius < 1. Will converge.\n"
     ]
    }
   ],
   "source": [
    "d = A.diagonal()\n",
    "D = np.diag(d)\n",
    "C = A - D\n",
    "\n",
    "# Check spectral radius\n",
    "m = npla.pinv(D)@C\n",
    "evs = npla.eig(m)[0]\n",
    "print(evs)\n",
    "\n",
    "if max(evs) < 1:\n",
    "    print(\"Spectral radius < 1. Will converge.\")\n",
    "else:\n",
    "    print(\"Spectral radius >= 1. Will not converge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      " [ 0.2406015  -0.00751879  0.03759399  0.65413534]\n",
      "\n",
      "All iterated residuals: \n",
      " [1.0, 1.4519108658968871, 1.2912751537070846, 0.9865560160549319, 0.8941390714131437, 0.69069042722823, 0.6183939725979902, 0.48319316304257875, 0.42806850186917, 0.3377617814670239, 0.29654865875975306, 0.23594048162245626, 0.20557155530601262, 0.16471760979850092, 0.14258428350857297, 0.11493716890519119, 0.09894310115933581, 0.08016703233839535, 0.0686868697808074, 0.05589504464393763, 0.047699085565958525, 0.03895976787655909, 0.03313387518080819, 0.027148442047978002, 0.02302190971046195, 0.018913677294891663, 0.01599931290166035, 0.013174193953853138, 0.011120864358881427, 0.009174903498598782, 0.007731101757595503, 0.006388793602497441, 0.005375266754515825, 0.004448207884024024, 0.003737714042181043, 0.0030967617118022157, 0.002599276204842514, 0.002155725668118326, 0.0018077278786830806, 0.001500540478481794, 0.001257311276884608, 0.0010444199521136288, 0.0008745352740619085, 0.0007269086347246559, 0.0006083211372077105, 0.0005059005175684057, 0.00042316173031299223, 0.00035207399141420616, 0.0002943710398015849, 0.00024501278767554595, 0.00020478432956770116, 0.0001705028498787265, 0.00014246538719972705, 0.00011864908642663112, 9.91131686650989e-05, 8.256358380278781e-05, 6.895429366753048e-05, 5.7452025382389656e-05, 4.797312745031391e-05, 3.997752635595025e-05, 3.337647759167334e-05, 2.7817698271705385e-05, 2.3221371232228084e-05, 1.9356282791663265e-05, 1.6156205941002305e-05, 1.3468489481650745e-05, 1.1240727914826979e-05, 9.37157455885454e-06, 7.820823736769848e-06, 6.520838825660139e-06, 5.44143088457707e-06, 4.537242693709496e-06, 3.7859590378248354e-06, 3.157028841223373e-06, 2.63415031102722e-06, 2.1966627438949137e-06, 1.832764937654618e-06, 1.5284342805547281e-06, 1.2751883000020826e-06, 1.0634790094851024e-06, 8.872438702875182e-07, 7.399630382753791e-07, 6.173232907808085e-07, 5.148612894511828e-07, 4.2951975154189223e-07, 3.5823638637331244e-07, 2.9885072642487124e-07, 2.492576556412654e-07, 2.0793427669604306e-07, 1.7343101612836633e-07, 1.4467662288609726e-07, 1.206714595860973e-07, 1.006632779422665e-07, 8.39618436207889e-08, 7.003967786430128e-08, 5.841966062005635e-08, 4.873236874311288e-08, 4.064768402339194e-08, 3.3907140625785095e-08, 2.828214453079474e-08, 2.359201511400168e-08, 1.967834924745455e-08, 1.6414932567482842e-08, 1.369193474892676e-08, 1.1421242180145326e-08, 9.52666371625422e-09]\n",
      "length =  106\n",
      "\n",
      "Last residual:  9.52666371625422e-09\n"
     ]
    }
   ],
   "source": [
    "#Run it using Jacobi - note, Jsolve() requires A to be a sparse matrix\n",
    "A = sparse.csr_matrix(A)\n",
    "solution = Jsolve(A, b, tol = 1e-8)\n",
    "print(\"x: \\n\",solution[0])\n",
    "print(\"\\nAll iterated residuals: \\n\", solution[1])\n",
    "print(\"length = \", len(solution[1]))\n",
    "print(\"\\nLast residual: \", solution[1][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
