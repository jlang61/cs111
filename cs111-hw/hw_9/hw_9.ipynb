{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements go here\n",
    "import numpy as np\n",
    "import numpy.linalg as npla\n",
    "from scipy import sparse\n",
    "def pagerank2(E, return_vector = False, max_iters = 1000, tolerance = 1e-6, m = 0.15):\n",
    "    \"\"\"compute page rank from dense adjacency matrix\n",
    "    Inputs:\n",
    "      E: adjacency matrix with links going from cols to rows.\n",
    "         E is a matrix of 0s and 1s, where E[i,j] = 1 means \n",
    "         that web page (vertex) j has a link to web page i.\n",
    "      return_vector = False: If True, return the eigenvector as well as the ranking.\n",
    "      max_iters = 1000: Maximum number of power iterations to do.\n",
    "      tolerance = 1e-6: Stop when the eigenvector norm changes by less than this.\n",
    "      m = 0.15: default\n",
    "      \n",
    "    Outputs:\n",
    "      ranking: Permutation giving the ranking, most important first\n",
    "      vector (only if return_vector is True): Dominant eigenvector of PageRank matrix\n",
    "    This computes page rank by the following steps:\n",
    "    1. Add links from any dangling vertices to all vertices.\n",
    "    2. Scale the columns to sum to 1.\n",
    "    3. Add a constant matrix to represent jumping at random 15% of the time.\n",
    "    4. Find the dominant eigenvector with the power method.\n",
    "    5. Sort the eigenvector to get the rankings.\n",
    "    \n",
    "    The function takes input E as a scipy csr_sparse matrix, and then never creates \n",
    "    a full matrix or any large matrix other than E.\n",
    "    \"\"\"\n",
    "\n",
    "# HERE ARE ALL THE TASKS YOU NEED TO FIGURE OUT!\n",
    "#################################################\n",
    "\n",
    "# 1. Check if E is a square matrix and that its entries are ONLY 1s and 0s, otherwise end this\n",
    "    assert E.shape[0] == E.shape[1], \"Not a square matrix\"\n",
    "    nnz = np.count_nonzero(E.data)\n",
    "    assert np.max(E) == 1 and np.sum(E) == nnz, \"Entries not only 1s and 0s\"\n",
    "    \n",
    "# 2. Check if E is a sparse matrix. If NOT, then convert it into one.\n",
    "    #sparse if number non zero is less than 1/3 of the total entries  \n",
    "    if (type(E) != sparse._csr.csr_matrix):\n",
    "      E = sparse.csr_matrix(E.data)\n",
    "      \n",
    "# 3. Calculate the outdegree \n",
    "    #calculate by summing up per row\n",
    "    n = E.shape[0]\n",
    "    outdegree = np.array(np.sum(E,0))\n",
    "    new_array = np.zeros(n)\n",
    "    for i in range(E.shape[1]):\n",
    "          new_array[i] = outdegree[0][i]\n",
    "    outdegree = new_array\n",
    "# 4. Get set up for the power iteration:\n",
    "#       create an initial vector (all 1s)\n",
    "#       make sure you know where outdegree is 0\n",
    "    n = E.shape[0]\n",
    "    e = np.ones(n)\n",
    "    v = e \n",
    "    there = np.where(outdegree == 0)\n",
    "    outdegree[there] = 1\n",
    "    for iteration in range(max_iters):\n",
    "        oldv = v\n",
    "      #Remember: The equation we are trying to solve is: MV = (1âˆ’m)(EV+FV) + m*SV,\n",
    "      #     where:  SV is the average of vector v\n",
    "      #             EV is matrix E multiplied by the normalized version of vector v\n",
    "      #             FV is a matrix that accounts for dangling vertices (i.e. where outdegree is 0 in E). \n",
    "      #                 Note that if there are no dangling nodes in E, F will always be 0 (easy case).\n",
    "      \n",
    "      \n",
    "      #Part 1: SV -- This last (and easiest) part of the equation essentially is just an \n",
    "      # \"average\" operator on the matrix v. By this I mean that every item in the vector is just \n",
    "      # The sum of the vector components divided by the number of nodes, which is an average.\n",
    "      # You can find SV with a simple and efficient alternative to actually making the dense S matrix and  \n",
    "      # multiplying it by v to get the same result.\n",
    "        SV = np.ones(n)\n",
    "        SV = SV * sum(v)/n\n",
    "        \n",
    "\n",
    "      #Part 2: EV  -- Multiply E by normalized v vector\n",
    "        EV = E @ (v /outdegree)\n",
    "        \n",
    "      #Part 3: FV -- In order to avoid having to actually construct the (likely sparse) F matrix,\n",
    "      # We will take advantage of the unique properties. Essentially we know that for a dangling node,\n",
    "      # the probability of landing on any other node is evenly split.  This translates to the values\n",
    "      # at the index of the dangling nodes in FV being one normalized unit of v less than all the other\n",
    "      # values at non-dangling indicies. You can do this in as little as 3 lines of code and thus \n",
    "      # calculate the FV vector without any matrix multiplication. \n",
    "        there_np = np.array(there)\n",
    "        FV = np.ones(n)*np.sum(v[there_np])\n",
    "        temp_zero = np.zeros(n)\n",
    "        temp_zero[there_np] = v[there_np] \n",
    "        #now remove number v[there] from all positions in FV listed in there\n",
    "        FV = FV - temp_zero\n",
    "        #divide FV by (n-1)\n",
    "        FV = FV /(n-1)\n",
    "        \n",
    "        \n",
    "      #Part 4: Calculate MV per the formula\n",
    "        MV = (1-m) * (EV + FV) + m * SV\n",
    "    \n",
    "    #5. And now you should be back to exactly where we were with pagerank1(), \n",
    "    #   so finish this up based on what we did in that function.\n",
    "        v = MV\n",
    "        eigval = npla.norm(v)\n",
    "        v = v / eigval\n",
    "        if (npla.norm(v - oldv) < tolerance):\n",
    "              break\n",
    "\n",
    "    if npla.norm(v - oldv) < tolerance:\n",
    "        print('Dominant eigenvalue is %f after %d iterations.\\n' % (eigval, iteration+1))\n",
    "    else:\n",
    "        print('Did not converge to tolerance %e after %d iterations.\\n' % (tolerance, max_iters))  \n",
    "    # finish it up here, just likae in pagerank1()\n",
    "    assert np.all(v > 0) or np.all(v < 0), 'Error: eigenvector is not all > 0 or < 0'\n",
    "    vector = np.abs(v)\n",
    "    \n",
    "    ranking = np.argsort(vector)[::-1]\n",
    "    if return_vector: \n",
    "      return ranking, vector  \n",
    "    else:\n",
    "      return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank1(E, return_vector = False, max_iters = 1000, tolerance = 1e-6):\n",
    "    \"\"\"compute page rank from dense adjacency matrix\n",
    "\n",
    "    Inputs:\n",
    "      E: adjacency matrix with links going from cols to rows.\n",
    "         E is a matrix of 0s and 1s, where E[i,j] = 1 means \n",
    "         that web page (vertex) j has a link to web page i.\n",
    "      return_vector = False: If True, return the eigenvector as well as the ranking.\n",
    "      max_iters = 1000: Maximum number of power iterations to do.\n",
    "      tolerance = 1e-6: Stop when the eigenvector norm changes by less than this.\n",
    "      \n",
    "    Outputs:\n",
    "      ranking: Permutation giving the ranking, most important first\n",
    "      vector (only if return_vector is True): Dominant eigenvector of PageRank matrix\n",
    "\n",
    "    This computes page rank by the following steps:\n",
    "    1. Add links from any dangling vertices to all vertices.\n",
    "    2. Scale the columns to sum to 1.\n",
    "    3. Add a constant matrix to represent jumping at random 15% of the time.\n",
    "    4. Find the dominant eigenvector with the power method.\n",
    "    5. Sort the eigenvector to get the rankings.\n",
    "\n",
    "    The homework problem asks you to rewrite this code so\n",
    "    it takes input E as a scipy csr_sparse matrix, and then never creates \n",
    "    a full matrix or any large matrix other than E.\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(E) is not np.ndarray:\n",
    "        print('Warning, converting input from type', type(E), 'to dense array.')\n",
    "        E = E.toarray()\n",
    "                \n",
    "    nnz = np.count_nonzero(E) # This call for sparse E may be different\n",
    "    outdegree = np.sum(E, axis=0)  # This call for sparse E may be different\n",
    "    nrows, n = E.shape\n",
    "\n",
    "    assert nrows == n, 'E must be square'\n",
    "    assert np.max(E) == 1 and np.sum(E) == nnz, 'E must contain only zeros and ones'\n",
    "    \n",
    "    #  1. Add links from any dangling vertices to all other vertices.\n",
    "    #     E + F will be the matrix with the added links.\n",
    "\n",
    "    F = np.zeros((n,n))\n",
    "    for j in range(n):\n",
    "        if outdegree[j] == 0:\n",
    "            F[:,j] = np.ones(n)\n",
    "            F[j,j] = 0\n",
    "    \n",
    "    #  2. Scale the columns to sum to 1 (i.e. normalization of E+F):\n",
    "\n",
    "    A = (E + F) / np.sum(E + F, axis=0)\n",
    "    \n",
    "    #  3. Add a constant matrix to represent jumping at random 15% of the time.\n",
    "\n",
    "    S = np.ones((n,n)) / n\n",
    "    m = 0.15\n",
    "    M = (1 - m) * A + m * S\n",
    "    \n",
    "    #  4. Find the dominant eigenvector using the power method.\n",
    "    #  Start with a vector all of whose entries are equal.\n",
    "\n",
    "    e = np.ones(n)\n",
    "    v = e / npla.norm(e)\n",
    "\n",
    "    for iteration in range(max_iters):\n",
    "        oldv = v\n",
    "        \n",
    "        v = M @ v\n",
    "        eigval = npla.norm(v)\n",
    "        v = v / eigval\n",
    "        \n",
    "        if npla.norm(v - oldv) < tolerance:\n",
    "            break\n",
    "    \n",
    "    if npla.norm(v - oldv) < tolerance:\n",
    "        print('Dominant eigenvalue is %f after %d iterations.\\n' % (eigval, iteration+1))\n",
    "    else:\n",
    "        print('Did not converge to tolerance %e after %d iterations.\\n' % (tolerance, max_iters))\n",
    "\n",
    "    # Check that the eigenvector elements are all the same sign, and make them positive\n",
    "    assert np.all(v > 0) or np.all(v < 0), 'Error: eigenvector is not all > 0 or < 0'\n",
    "    vector = np.abs(v)\n",
    "        \n",
    "    #  5. Sort the eigenvector and reverse the permutation to get the rankings.\n",
    "    ranking = np.argsort(vector)[::-1]\n",
    "\n",
    "    if return_vector:\n",
    "        return ranking, vector\n",
    "    else:\n",
    "        return ranking\n",
    "\n",
    "# end of pagerank1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant eigenvalue is 1.000000 after 19 iterations.\n",
      "\n",
      "r = [0 2 3 1]\n",
      "v = [0.69648305 0.26828106 0.54477799 0.38230039]\n",
      "Dominant eigenvalue is 1.000000 after 19 iterations.\n",
      "\n",
      "r = [0 2 3 1]\n",
      "v = [0.69648305 0.26828106 0.54477799 0.38230039]\n"
     ]
    }
   ],
   "source": [
    "# Non-iterative approach gave us:  \n",
    "# r = [0 2 3 1]\n",
    "\n",
    "E = np.load('PageRankEG1.npy')\n",
    "r, v = pagerank1(E, return_vector = True)\n",
    "print('r =', r)\n",
    "print('v =', v)\n",
    "r, v = pagerank2(E, return_vector = True)\n",
    "print('r =', r)\n",
    "print('v =', v)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "138833874f2dc7c1a2fe589d9c55b0aff635bc609cbe7c4d1d123c8b54c76836"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
